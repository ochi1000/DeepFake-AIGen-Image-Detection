{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQXEm9CQ4jgFV8GOaqtAc0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ochi1000/DeepFake-AIGen-Image-Detection/blob/main/DeepFakeDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-e33s-z3QPt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "\n",
        "# Utility: Unzip Images\n",
        "def extract_zip(zip_path, extract_to):\n",
        "    \"\"\"\n",
        "    Extracts the zip file to the specified directory if not already extracted.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(extract_to):\n",
        "        os.makedirs(extract_to, exist_ok=True)\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "        print(f\"Extracted {zip_path} to {extract_to}\")\n",
        "    else:\n",
        "        print(f\"Directory {extract_to} already exists. Skipping extraction.\")\n",
        "\n",
        "# Custom Dataset\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with image names and labels.\n",
        "            img_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transforms to be applied on an image.\n",
        "        \"\"\"\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.data.iloc[idx]['image_name']\n",
        "        label = int(self.data.iloc[idx]['label'])\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Training & Evaluation Functions\n",
        "def train(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += torch.sum(preds == labels.data)\n",
        "        total += labels.size(0)\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct.double() / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += torch.sum(preds == labels.data)\n",
        "            total += labels.size(0)\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = correct.double() / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "# Main Pipeline\n",
        "def main():\n",
        "    # Paths: Adjust these paths as needed.\n",
        "    zip_path = 'images.zip'\n",
        "    img_dir = 'images'\n",
        "    train_csv = 'train.csv'\n",
        "    test_csv = 'test.csv'\n",
        "\n",
        "    # Extract images from the zip file\n",
        "    extract_zip(zip_path, img_dir)\n",
        "\n",
        "    # Data transformations: Resize images, apply augmentations to training images, and normalize.\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'test': transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    }\n",
        "\n",
        "    # Create datasets and dataloaders\n",
        "    train_dataset = ImageDataset(train_csv, img_dir, transform=data_transforms['train'])\n",
        "    test_dataset = ImageDataset(test_csv, img_dir, transform=data_transforms['test'])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
        "\n",
        "    # Device configuration\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load a pre-trained ResNet18 model and modify the final fully connected layer for 2 classes.\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_features, 2)\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "    # Training loop\n",
        "    num_epochs = 10\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
        "        test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\\n\")\n",
        "\n",
        "    # Optionally, save the trained model\n",
        "    torch.save(model.state_dict(), \"model_weights.pth\")\n",
        "    print(\"Model training complete and weights saved.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    }
  ]
}